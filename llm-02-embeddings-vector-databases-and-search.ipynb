{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53482,"databundleVersionId":6201832,"sourceType":"competition"},{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":1428159,"sourceType":"datasetVersion","datasetId":836401},{"sourceId":6344901,"sourceType":"datasetVersion","datasetId":3653083}],"dockerImageVersionId":30513,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ⚡ Further Notebooks In This Course ⚡","metadata":{}},{"cell_type":"markdown","source":"**Notebooks:**\n1. [LLM 01 - How to use LLMs with Hugging Face](https://www.kaggle.com/code/aliabdin1/llm-01-llms-with-hugging-face)\n2. [LLM 02 - Embeddings, Vector Databases, and Search](https://www.kaggle.com/code/aliabdin1/llm-02-embeddings-vector-databases-and-search)\n3. [LLM 03 - Building LLM Chain](https://www.kaggle.com/code/aliabdin1/llm-03-building-llm-chain)\n4. [LLM 04a - Fine-tuning LLMs](https://www.kaggle.com/code/aliabdin1/llm-04a-fine-tuning-llms)\n4. [LLM 04b - Evaluating LLMs](https://www.kaggle.com/code/aliabdin1/llm-04b-evaluating-llms)\n5. [LLM 05 - Biased LLMs and Society](https://www.kaggle.com/code/aliabdin1/llm-05-llms-and-society)\n6. [LLM 06 - LLMOps](https://www.kaggle.com/code/aliabdin1/llm-06-llmops)\n\n**Hands-on Lab Notebooks:**\n1. [LLM 01L - How to use LLMs with Hugging Face Lab](https://www.kaggle.com/code/aliabdin1/llm-01l-llms-with-hugging-face-lab)\n2. [LLM 02L - Embeddings, Vector Databases, and Search Lab](https://www.kaggle.com/code/aliabdin1/llm-02l-embeddings-vector-databases-and-search)\n3. [LLM 03L - Building LLM Chains Lab](https://www.kaggle.com/code/aliabdin1/llm-03l-building-llm-chains-lab)\n4. [LLM 04L - Fine-tuning LLMs Lab](https://www.kaggle.com/code/aliabdin1/llm-04l-fine-tuning-llms-lab)\n5. [LLM 05L - Biased LLMs and Society Lab](https://www.kaggle.com/code/aliabdin1/llm-05l-llms-and-society-lab)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b29adc71-b1ae-41fb-8d60-5183aba40745","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":"Reference\n- https://www.kaggle.com/code/aliabdin1/llm-02-embeddings-vector-databases-and-search\n- https://youtu.be/GKqtMBkFotA?si=mGxXnpDdFf1pBlUn\n- https://github.com/databricks-academy/large-language-models","metadata":{}},{"cell_type":"markdown","source":"# Embeddings, Vector Databases, and Search\n\nConverting text into embedding vectors is the first step to any text processing pipeline. As the amount of text gets larger, there is often a need to save these embedding vectors into a dedicated vector index or library, so that developers won't have to recompute the embeddings and the retrieval process is faster. We can then search for documents based on our intended query and pass these relevant documents into a language model (LM) as additional context. We also refer to this context as supplying the LM with \"state\" or \"memory\". The LM then generates a response based on the additional context it receives! \n\nIn this notebook, we will implement the full workflow of text vectorization, vector search, and question answering workflow. While we use [FAISS](https://faiss.ai/) (vector library) and [ChromaDB](https://docs.trychroma.com/) (vector database), and a Hugging Face model, know that you can easily swap these tools out for your preferred tools or models!\n\n<img src=\"https://files.training.databricks.com/images/llm/updated_vector_search.png\" width=1000 target=\"_blank\" > \n\n### ![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png) Learning Objectives\n1. Implement the workflow of reading text, converting text to embeddings, saving them to FAISS and ChromaDB \n2. Query for similar documents using FAISS and ChromaDB \n3. Apply a Hugging Face language model for question answering!","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"89833fe5-7ecd-4dfd-ae08-80267f4ddd98","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":"Restart kernel after running the following cell","metadata":{}},{"cell_type":"code","source":"# ! pip install -U git+https://github.com/huggingface/transformers.git --quiet\n# ! pip install -U git+https://github.com/huggingface/accelerate.git --quiet","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:38.785123Z","iopub.execute_input":"2023-08-31T11:50:38.785723Z","iopub.status.idle":"2023-08-31T11:50:38.790768Z","shell.execute_reply.started":"2023-08-31T11:50:38.785689Z","shell.execute_reply":"2023-08-31T11:50:38.789576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %pip install faiss-cpu==1.7.4 sentence_transformers --quiet","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"dec485a4-a344-49b6-87a9-d90cf84f76cb","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:50:38.792434Z","iopub.execute_input":"2023-08-31T11:50:38.792875Z","iopub.status.idle":"2023-08-31T11:50:38.80495Z","shell.execute_reply.started":"2023-08-31T11:50:38.792844Z","shell.execute_reply":"2023-08-31T11:50:38.80385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Reading data\n\nIn this section, we are going to use the data on <a href=\"https://newscatcherapi.com/\" target=\"_blank\">news topics collected by the NewsCatcher team</a>, who collect and index news articles and release them to the open-source community. The dataset can be downloaded from <a href=\"https://www.kaggle.com/kotartemiy/topic-labeled-news-dataset\" target=\"_blank\">Kaggle</a>.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1991f2ec-5d23-476c-be89-2e110206eb22","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"import pandas as pd\n\n#pdf = pd.read_csv(\"../input/topic-labeled-news-dataset/labelled_newscatcher_dataset.csv\", sep=\";\")\npdf = pd.read_csv(\"/kaggle/input/omdena-faq-chatbot-training-data/omdena_faq_training_data_1 - Sheet1 (6).csv\")\npdf[\"id\"] = pdf.index\ndisplay(pdf)","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"180e7264-19e6-47ac-a3dd-7167b33821bc","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:50:38.806397Z","iopub.execute_input":"2023-08-31T11:50:38.806958Z","iopub.status.idle":"2023-08-31T11:50:38.872313Z","shell.execute_reply.started":"2023-08-31T11:50:38.806926Z","shell.execute_reply":"2023-08-31T11:50:38.871216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdf.iloc[2,4]","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:38.87609Z","iopub.execute_input":"2023-08-31T11:50:38.876751Z","iopub.status.idle":"2023-08-31T11:50:38.884211Z","shell.execute_reply.started":"2023-08-31T11:50:38.876708Z","shell.execute_reply":"2023-08-31T11:50:38.883074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vector Library: FAISS\n\nVector libraries are often sufficient for small, static data. Since it's not a full-fledged database solution, it doesn't have the CRUD (Create, Read, Update, Delete) support. Once the index has been built, if there are more vectors that need to be added/removed/edited, the index has to be rebuilt from scratch. \n\nThat said, vector libraries are easy, lightweight, and fast to use. Examples of vector libraries are [FAISS](https://faiss.ai/), [ScaNN](https://github.com/google-research/google-research/tree/master/scann), [ANNOY](https://github.com/spotify/annoy), and [HNSM](https://arxiv.org/abs/1603.09320).\n\nFAISS has several ways for similarity search: L2 (Euclidean distance), cosine similarity. You can read more about their implementation on their [GitHub](https://github.com/facebookresearch/faiss/wiki/Getting-started#searching) page or [blog post](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/). They also published their own [best practice guide here](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index).\n\nIf you'd like to read up more on the comparisons between vector libraries and databases, [here is a good blog post](https://weaviate.io/blog/vector-library-vs-vector-database#feature-comparison---library-versus-database).","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f02db3f-2381-4e8c-81bf-b1228261227d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":"The overall workflow of FAISS is captured in the diagram below. \n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*ouf0eyQskPeGWIGm\" width=700>\n\nSource: [How to use FAISS to build your first similarity search by Asna Shafiq](https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772).","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8aae6ef7-2cf8-4e20-8fdf-9cf1d1b63372","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"pdf_subset = pdf.dropna(subset=['Answers']).copy()\npdf_subset['QNA'] = pdf_subset.apply(lambda row: f\"Question: {row['Questions']}, Answer: {row['Answers']}\", axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:38.885424Z","iopub.execute_input":"2023-08-31T11:50:38.885728Z","iopub.status.idle":"2023-08-31T11:50:38.912693Z","shell.execute_reply.started":"2023-08-31T11:50:38.885702Z","shell.execute_reply":"2023-08-31T11:50:38.911646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdf_subset['QNA'][0]","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:38.913911Z","iopub.execute_input":"2023-08-31T11:50:38.914266Z","iopub.status.idle":"2023-08-31T11:50:38.922533Z","shell.execute_reply.started":"2023-08-31T11:50:38.914236Z","shell.execute_reply":"2023-08-31T11:50:38.921704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import InputExample\n\ndef example_create_fn(doc1: pd.Series) -> InputExample:\n    \"\"\"\n    Helper function that outputs a sentence_transformer guid, label, and text\n    \"\"\"\n    return InputExample(texts=[doc1])\n\nfaiss_train_examples = pdf_subset.apply(\n    lambda x: example_create_fn(x[\"Questions\"]), axis=1\n).tolist()","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c47997f0-e52b-4853-95b6-02850572b5ea","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:50:38.923903Z","iopub.execute_input":"2023-08-31T11:50:38.924463Z","iopub.status.idle":"2023-08-31T11:50:45.336015Z","shell.execute_reply.started":"2023-08-31T11:50:38.924432Z","shell.execute_reply":"2023-08-31T11:50:45.334729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdf_subset.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:45.337411Z","iopub.execute_input":"2023-08-31T11:50:45.338208Z","iopub.status.idle":"2023-08-31T11:50:45.345574Z","shell.execute_reply.started":"2023-08-31T11:50:45.338161Z","shell.execute_reply":"2023-08-31T11:50:45.344293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdf.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:45.347583Z","iopub.execute_input":"2023-08-31T11:50:45.348494Z","iopub.status.idle":"2023-08-31T11:50:45.363325Z","shell.execute_reply.started":"2023-08-31T11:50:45.348457Z","shell.execute_reply":"2023-08-31T11:50:45.362185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(faiss_train_examples[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:45.365083Z","iopub.execute_input":"2023-08-31T11:50:45.365566Z","iopub.status.idle":"2023-08-31T11:50:45.379567Z","shell.execute_reply.started":"2023-08-31T11:50:45.365531Z","shell.execute_reply":"2023-08-31T11:50:45.378537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 2: Vectorize text into embedding vectors\nWe will be using `Sentence-Transformers` [library](https://www.sbert.net/) to load a language model to vectorize our text into embeddings. The library hosts some of the most popular transformers on [Hugging Face Model Hub](https://huggingface.co/sentence-transformers).\nHere, we are using the `model = SentenceTransformer(\"all-MiniLM-L6-v2\")` to generate embeddings.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9d2cb3f0-2a12-4694-9d5e-900cf388222e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"mkdir cache","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:45.381009Z","iopub.execute_input":"2023-08-31T11:50:45.381379Z","iopub.status.idle":"2023-08-31T11:50:46.490802Z","shell.execute_reply.started":"2023-08-31T11:50:45.381346Z","shell.execute_reply":"2023-08-31T11:50:46.489263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pdf_subset.QNA.values.tolist()[:3]","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:46.493369Z","iopub.execute_input":"2023-08-31T11:50:46.49387Z","iopub.status.idle":"2023-08-31T11:50:46.503313Z","shell.execute_reply.started":"2023-08-31T11:50:46.493823Z","shell.execute_reply":"2023-08-31T11:50:46.50208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All Sentence Models list: https://www.sbert.net/docs/pretrained_models.html","metadata":{}},{"cell_type":"code","source":"","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77020e02-ff1f-4c0d-b03c-24159678b8d0","inputWidgets":{},"title":""},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\n   #\"all-MiniLM-L6-v2\", \n   \"all-distilroberta-v1\",\n    cache_folder=\"../working/cache/\"\n)\nmodel.save(\"all-distilroberta-v1-model.pkl\")\nmodel = SentenceTransformer.load(\"all-distilroberta-v1-model.pkl\")\n\nfaiss_title_embedding = model.encode(pdf_subset.Questions.values.tolist())\nlen(faiss_title_embedding), len(faiss_title_embedding[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:50:46.511673Z","iopub.execute_input":"2023-08-31T11:50:46.512052Z","iopub.status.idle":"2023-08-31T11:51:09.53593Z","shell.execute_reply.started":"2023-08-31T11:50:46.512022Z","shell.execute_reply":"2023-08-31T11:51:09.53514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faiss_title_embedding.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.537398Z","iopub.execute_input":"2023-08-31T11:51:09.537988Z","iopub.status.idle":"2023-08-31T11:51:09.545065Z","shell.execute_reply.started":"2023-08-31T11:51:09.537956Z","shell.execute_reply":"2023-08-31T11:51:09.543905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Step 3: Saving embedding vectors to FAISS index\nBelow, we create the FAISS index object based on our embedding vectors, normalize vectors, and add these vectors to the FAISS index.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6a9c3a9-eac5-4584-8372-4b3d7cc339a3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"import numpy as np\nimport faiss\n\npdf_to_index = pdf_subset.set_index([\"id\"], drop=False)\nid_index = np.array(pdf_to_index.id.values).flatten().astype(\"int\")\n\ncontent_encoded_normalized = faiss_title_embedding.copy()\nfaiss.normalize_L2(content_encoded_normalized)\n\n# Index1DMap translates search results to IDs: https://faiss.ai/cpp_api/file/IndexIDMap_8h.html#_CPPv4I0EN5faiss18IndexIDMapTemplateE\n# The IndexFlatIP below builds index\nindex_content = faiss.IndexIDMap(faiss.IndexFlatIP(len(faiss_title_embedding[0])))\nindex_content.add_with_ids(content_encoded_normalized, id_index)","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"54e2e5dc-58dd-48d2-9828-f8fc8cbdf49b","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:51:09.546514Z","iopub.execute_input":"2023-08-31T11:51:09.546859Z","iopub.status.idle":"2023-08-31T11:51:09.586464Z","shell.execute_reply.started":"2023-08-31T11:51:09.546829Z","shell.execute_reply":"2023-08-31T11:51:09.585283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the index\nfaiss.write_index(index_content, \"index.faiss\")\n\n# Load the index\nindex_content = faiss.read_index(\"index.faiss\")","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.589364Z","iopub.execute_input":"2023-08-31T11:51:09.590325Z","iopub.status.idle":"2023-08-31T11:51:09.597537Z","shell.execute_reply.started":"2023-08-31T11:51:09.590277Z","shell.execute_reply":"2023-08-31T11:51:09.596376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_encoded_normalized.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.598847Z","iopub.execute_input":"2023-08-31T11:51:09.599221Z","iopub.status.idle":"2023-08-31T11:51:09.609467Z","shell.execute_reply.started":"2023-08-31T11:51:09.599187Z","shell.execute_reply":"2023-08-31T11:51:09.60808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"faiss_title_embedding.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.610826Z","iopub.execute_input":"2023-08-31T11:51:09.611274Z","iopub.status.idle":"2023-08-31T11:51:09.622359Z","shell.execute_reply.started":"2023-08-31T11:51:09.61124Z","shell.execute_reply":"2023-08-31T11:51:09.621221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Search for relevant documents\n\nWe define a search function below to first vectorize our query text, and then search for the vectors with the closest distance.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"241c55b6-7b53-4e5e-97d1-ce03717beeaa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"def search_content(query, pdf_to_index, k=5):\n    query_vector = model.encode([query])\n    faiss.normalize_L2(query_vector)\n\n    # We set k to limit the number of vectors we want to return\n    top_k = index_content.search(query_vector, k)\n    ids = top_k[1][0].tolist()\n    similarities = top_k[0][0].tolist()\n    results = pdf_to_index.loc[ids]\n    results[\"similarities\"] = similarities\n    return results","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19a35eb0-2b6c-481e-ab7e-4aaf1e2a35f4","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:51:09.623717Z","iopub.execute_input":"2023-08-31T11:51:09.624713Z","iopub.status.idle":"2023-08-31T11:51:09.633202Z","shell.execute_reply.started":"2023-08-31T11:51:09.62467Z","shell.execute_reply":"2023-08-31T11:51:09.632102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tada! Now you can query for similar content! Notice that you did not have to configure any database networks beforehand nor pass in any credentials. FAISS works locally with your code.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2bf1edc7-07f5-41b6-802b-bbcc9855747f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"results = search_content(\"What is the process to join Omdena School?\", pdf_to_index)\nresults['Answers']","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77bbaaf9-e3f5-4aec-acde-4a7224e8589e","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:51:09.63465Z","iopub.execute_input":"2023-08-31T11:51:09.635011Z","iopub.status.idle":"2023-08-31T11:51:09.716548Z","shell.execute_reply.started":"2023-08-31T11:51:09.634979Z","shell.execute_reply":"2023-08-31T11:51:09.715682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results['Answers'].iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.717883Z","iopub.execute_input":"2023-08-31T11:51:09.718859Z","iopub.status.idle":"2023-08-31T11:51:09.723958Z","shell.execute_reply.started":"2023-08-31T11:51:09.718824Z","shell.execute_reply":"2023-08-31T11:51:09.723162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Up until now, we haven't done the last step of conducting Q/A with a language model yet. We are going to demonstrate this with Chroma, a vector database.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19ef9158-ee09-4237-b473-81e669ad6e47","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":"## Prompt engineering for question answering \n\nNow that we have identified documents about space from the news dataset, we can pass these documents as additional context for a language model to generate a response based on them! \n\nWe first need to pick a `text-generation` model. Below, we use a Hugging Face model. You can also use OpenAI as well, but you will need to get an Open AI token and [pay based on the number of tokens](https://openai.com/pricing).","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f02e3fdf-9836-4d54-9baf-aad4a3dc9c08","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"#!pip uninstall -y accelerate","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.725317Z","iopub.execute_input":"2023-08-31T11:51:09.726239Z","iopub.status.idle":"2023-08-31T11:51:09.738503Z","shell.execute_reply.started":"2023-08-31T11:51:09.726204Z","shell.execute_reply":"2023-08-31T11:51:09.737254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade accelerate","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.74004Z","iopub.execute_input":"2023-08-31T11:51:09.74046Z","iopub.status.idle":"2023-08-31T11:51:09.750114Z","shell.execute_reply.started":"2023-08-31T11:51:09.740426Z","shell.execute_reply":"2023-08-31T11:51:09.74896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's where prompt engineering, which is developing prompts, comes in. We pass in the context in our `prompt_template` but there are numerous ways to write a prompt. Some prompts may generate better results than the others and it requires some experimentation to figure out how best to talk to the model. Each language model behaves differently to prompts. \n\nOur prompt template below is inspired from a [2023 paper on program-aided language model](https://arxiv.org/pdf/2211.10435.pdf). The authors have provided their sample prompt template [here](https://github.com/reasoning-machines/pal/blob/main/pal/prompt/date_understanding_prompt.py).\n\nThe following links also provide some helpful guidance on prompt engineering: \n- [Prompt engineering with OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n- [GitHub repo that compiles best practices to interact with ChatGPT](https://github.com/f/awesome-chatgpt-prompts)","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd7f3221-e519-4f1f-a612-2bbcbb1b9f66","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"results['Answers']","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.751637Z","iopub.execute_input":"2023-08-31T11:51:09.752018Z","iopub.status.idle":"2023-08-31T11:51:09.7667Z","shell.execute_reply.started":"2023-08-31T11:51:09.751987Z","shell.execute_reply":"2023-08-31T11:51:09.765486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"question = \"how can i join\"\nresults = search_content(question, pdf_to_index)\ncontext = \" \".join([f\"#{str(i)}\" for i in results['Answers']])[:2014]\n#prompt_template = f\"Relevant context: {context}\\n\\n provide Answer to the question in a paragraph: {question}\"\nprompt_template = f\"Relevant context: {context}\\n\\n Answer the question in detail: {question}\"\n","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"464d17dc-24d7-429b-821d-27fbb7d919b4","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:51:09.768205Z","iopub.execute_input":"2023-08-31T11:51:09.768659Z","iopub.status.idle":"2023-08-31T11:51:09.840014Z","shell.execute_reply.started":"2023-08-31T11:51:09.768593Z","shell.execute_reply":"2023-08-31T11:51:09.838841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_template","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.841962Z","iopub.execute_input":"2023-08-31T11:51:09.842427Z","iopub.status.idle":"2023-08-31T11:51:09.849218Z","shell.execute_reply.started":"2023-08-31T11:51:09.842385Z","shell.execute_reply":"2023-08-31T11:51:09.848352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5ForConditionalGeneration\n\ntokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\nmodel_text = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n\ninput_text = prompt_template\n#input_text = \"translate English to German: How old are you?\"\n#input_text = \"Summarize text:\"+text#prompt_template\ninput_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n\noutputs = model_text.generate(input_ids, max_new_tokens = 2024,temperature=0.1, do_sample=True)\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:09.850469Z","iopub.execute_input":"2023-08-31T11:51:09.851389Z","iopub.status.idle":"2023-08-31T11:51:14.269803Z","shell.execute_reply.started":"2023-08-31T11:51:09.851355Z","shell.execute_reply":"2023-08-31T11:51:14.268636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openai","metadata":{"execution":{"iopub.status.busy":"2023-09-06T08:24:30.341966Z","iopub.execute_input":"2023-09-06T08:24:30.342974Z","iopub.status.idle":"2023-09-06T08:24:46.33962Z","shell.execute_reply.started":"2023-09-06T08:24:30.342939Z","shell.execute_reply":"2023-09-06T08:24:46.337856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"openai\")\nimport openai\n\nopenai.api_key = secret_value_0\n\nmodel_engine = \"text-davinci-002\"\nprompt_template = \"what is omdena project\"#prompt_template\n\nresponse = openai.Completion.create(\n    engine=model_engine,\n    prompt=prompt_template,\n    max_tokens=124,\n    temperature=0.8,\n    n=1,\n    stop=None,\n)\n\nprint(response.choices[0].text)","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e698c3f9-3f88-4d34-8501-f6d0cee60c7e","inputWidgets":{},"title":""},"execution":{"iopub.status.busy":"2023-08-31T11:51:28.903579Z","iopub.execute_input":"2023-08-31T11:51:28.903963Z","iopub.status.idle":"2023-08-31T11:51:30.418693Z","shell.execute_reply.started":"2023-08-31T11:51:28.903922Z","shell.execute_reply":"2023-08-31T11:51:30.417518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yay, you have just completed the implementation of your first text vectorization, search, and question answering workflow (that requires prompt engineering)!\n\nIn the lab, you will apply your newly gained knowledge to a different dataset. You can also check out the optional modules on Pinecone and Weaviate to learn how to set up vector databases that offer enterprise offerings.","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f7039cc-4567-4925-92e8-6ceab81fa724","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":"&copy; 2023 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>","metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e4d049f-0691-4c7e-9639-1e951c3d5954","inputWidgets":{},"title":""}}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"openai\")\nimport openai\n# Your job is to extract the user intent and create a single question\nopenai.api_key = secret_value_0\nmessages=[\n    {\"role\": \"system\", \"content\": f\"our job is to extract the user intent and create a single question\"},\n    {\"role\": \"user\", \"content\": \"1 what is omdena school\"},\n    {\"role\": \"user\", \"content\": \"2 what is local chapter \"},\n     {\"role\": \"user\", \"content\": \"3 how do i join\"}\n  ]\nresponse = openai.ChatCompletion.create(\n                model=\"gpt-3.5-turbo\",\n                messages=   messages,\n                temperature=0,\n                max_tokens=10,\n                top_p=1,\n                frequency_penalty=0,\n                presence_penalty=0\n                )\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T08:26:38.324033Z","iopub.execute_input":"2023-09-06T08:26:38.324639Z","iopub.status.idle":"2023-09-06T08:26:38.926521Z","shell.execute_reply.started":"2023-09-06T08:26:38.324596Z","shell.execute_reply":"2023-09-06T08:26:38.925046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:32.56348Z","iopub.status.idle":"2023-08-31T11:51:32.564088Z","shell.execute_reply.started":"2023-08-31T11:51:32.563737Z","shell.execute_reply":"2023-08-31T11:51:32.563758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response.choices[0]['message']['content'].strip()","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:32.566165Z","iopub.status.idle":"2023-08-31T11:51:32.56665Z","shell.execute_reply.started":"2023-08-31T11:51:32.566431Z","shell.execute_reply":"2023-08-31T11:51:32.566454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Convert the response object to a JSON string\nresponse_json = json.dumps(response)\n\n# Extract the content of the first choice\ncontent = response_json[\"choices\"][0][\"message\"][\"content\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-31T11:51:32.568618Z","iopub.status.idle":"2023-08-31T11:51:32.569078Z","shell.execute_reply.started":"2023-08-31T11:51:32.568865Z","shell.execute_reply":"2023-08-31T11:51:32.568887Z"},"trusted":true},"execution_count":null,"outputs":[]}]}